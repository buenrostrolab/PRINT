{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fac34a44-2699-4069-8699-8185e3f16141",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import scprinter as scp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import pyBigWig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concurrent.futures import *\n",
    "from tqdm.auto import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8787af8-83d5-4e99-ac1e-bd9782f46a21",
   "metadata": {},
   "source": [
    "# Train a finetuned TFBS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "928a2e21-c45a-4273-9544-2e976b16c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['attr.count.shap_hypo_0_.0.85.bigwig',\n",
    "         'attr.just_sum.shap_hypo_0-30_.0.85.bigwig',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0338c994-8c93-4213-8652-3f2834f97aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_paths = {\n",
    "    'HepG2_0': \"/data/rzhang/PRINT_rev/HepG2/TF_prediction.tsv\",\n",
    "    'HepG2_1': \"/data/rzhang/PRINT_rev/HepG2/TF_prediction.tsv\",\n",
    "    'HepG2_2': \"/data/rzhang/PRINT_rev/HepG2/TF_prediction.tsv\",\n",
    "    'HepG2_3': \"/data/rzhang/PRINT_rev/HepG2/TF_prediction.tsv\",\n",
    "    'HepG2_4': \"/data/rzhang/PRINT_rev/HepG2/TF_prediction.tsv\",\n",
    "    'GM12878_0': \"/data/rzhang/PRINT_rev/GM12878/GM12878_pred_data.tsv\",\n",
    "    'GM12878_1': \"/data/rzhang/PRINT_rev/GM12878/GM12878_pred_data.tsv\",\n",
    "    'GM12878_2': \"/data/rzhang/PRINT_rev/GM12878/GM12878_pred_data.tsv\",\n",
    "    'GM12878_3': \"/data/rzhang/PRINT_rev/GM12878/GM12878_pred_data.tsv\",\n",
    "    'GM12878_4': \"/data/rzhang/PRINT_rev/GM12878/GM12878_pred_data.tsv\",\n",
    "    'K562': \"/data/rzhang/PRINT_rev/K562/K562_pred_data.tsv\",\n",
    "    'A549': \"/data/rzhang/PRINT_rev/A549/A549_pred_data.tsv\"\n",
    "}\n",
    "peaks_path = {\n",
    "    'HepG2_0': \"/data/rzhang/PRINT_rev/HepG2/peaks.bed\",\n",
    "    'HepG2_1': \"/data/rzhang/PRINT_rev/HepG2/peaks.bed\",\n",
    "    'HepG2_2': \"/data/rzhang/PRINT_rev/HepG2/peaks.bed\",\n",
    "    'HepG2_3': \"/data/rzhang/PRINT_rev/HepG2/peaks.bed\",\n",
    "    'HepG2_4': \"/data/rzhang/PRINT_rev/HepG2/peaks.bed\",\n",
    "    'GM12878_0': \"/data/rzhang/PRINT_rev/GM12878/peaks.bed\",\n",
    "    'GM12878_1': \"/data/rzhang/PRINT_rev/GM12878/peaks.bed\",\n",
    "    'GM12878_2': \"/data/rzhang/PRINT_rev/GM12878/peaks.bed\",\n",
    "    'GM12878_3': \"/data/rzhang/PRINT_rev/GM12878/peaks.bed\",\n",
    "    'GM12878_4': \"/data/rzhang/PRINT_rev/GM12878/peaks.bed\",\n",
    "    'K562': \"/data/rzhang/PRINT_rev/K562/peaks.bed\",\n",
    "    'A549': \"/data/rzhang/PRINT_rev/A549/peaks.bed\",\n",
    "}\n",
    "\n",
    "model_name = {\n",
    "    'HepG2_0': [\"/data/rzhang/PRINT_rev/HepG2/final_model/HepG2_fold0-crimson-bao-8.pt_deepshap\"],\n",
    "    'HepG2_1': [\"/data/rzhang/PRINT_rev/HepG2/final_model/HepG2_fold1-auspicious-rocket-9.pt_deepshap\"],\n",
    "    'HepG2_2': [\"/data/rzhang/PRINT_rev/HepG2/final_model/HepG2_fold2-prosperous-fish-8.pt_deepshap\"],\n",
    "    'HepG2_3': [\"/data/rzhang/PRINT_rev/HepG2/final_model/HepG2_fold3-prosperous-bao-11.pt_deepshap\"],\n",
    "    'HepG2_4': [\"/data/rzhang/PRINT_rev/HepG2/final_model/HepG2_fold4-radiant-paper-12.pt_deepshap\"],\n",
    "    'GM12878_0': [\"/data/rzhang/PRINT_rev/GM12878/final_model/GM12878_fold0-flashing-envelope-23.pt_deepshap\"],\n",
    "    'GM12878_1': [\"/data/rzhang/PRINT_rev/GM12878/final_model/GM12878_fold1-thriving-dog-24.pt_deepshap\"],\n",
    "    'GM12878_2': [\"/data/rzhang/PRINT_rev/GM12878/final_model/GM12878_fold2-dazzling-dog-21.pt_deepshap\"],\n",
    "    'GM12878_3': [\"/data/rzhang/PRINT_rev/GM12878/final_model/GM12878_fold3-vivid-chrysanthemum-21.pt_deepshap\"],\n",
    "    'GM12878_4': [\"/data/rzhang/PRINT_rev/GM12878/final_model/GM12878_fold4-legendary-festival-25.pt_deepshap\"],\n",
    "\n",
    "    'K562': [\"/data/rzhang/PRINT_rev/K562/final_model/K562_fold0-flashing-snake-6.pt_deepshap_wo_norm\",\n",
    "             \"/data/rzhang/PRINT_rev/K562/final_model/K562_fold1-abundant-envelope-1.pt_deepshap_wo_norm\",\n",
    "             \"/data/rzhang/PRINT_rev/K562/final_model/K562_fold2-luminous-fireworks-1.pt_deepshap_wo_norm\",\n",
    "             \"/data/rzhang/PRINT_rev/K562/final_model/K562_fold3-auspicious-laughter-1.pt_deepshap_wo_norm\",\n",
    "             \"/data/rzhang/PRINT_rev/K562/final_model/K562_fold4-glistening-peony-7.pt_deepshap_wo_norm\"],\n",
    "    'A549': [\"/data/rzhang/PRINT_rev/A549/final_model/A549_fold0-glittering-wonton-28.pt_deepshap\",\n",
    "             \"/data/rzhang/PRINT_rev/A549/final_model/A549_fold1-cheerful-fish-29.pt_deepshap\",\n",
    "             \"/data/rzhang/PRINT_rev/A549/final_model/A549_fold2-filigreed-dog-27.pt_deepshap\",\n",
    "             \"/data/rzhang/PRINT_rev/A549/final_model/A549_fold3-crimson-fuse-26.pt_deepshap\",\n",
    "             \"/data/rzhang/PRINT_rev/A549/final_model/A549_fold4-radiant-pig-30.pt_deepshap\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "279927f6-22f5-4e01-8eaf-4c69d5d56e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_TF_loci(path):\n",
    "    TF_prediction = pd.read_csv(path, sep='\\t')\n",
    "    if 'range' in TF_prediction.columns:\n",
    "        ranges = pd.DataFrame([re.split(':|-', xx) for xx in TF_prediction['range']])\n",
    "        ranges = ranges[[0,1,2,3]]\n",
    "        v = np.array(ranges[3])\n",
    "        v[v == ''] = '-'\n",
    "        ranges[3] = v\n",
    "        ranges.columns = ['chrom','start','end', 'strand']\n",
    "        ranges['start'] = ranges['start'].astype('int')\n",
    "        ranges['end'] = ranges['end'].astype('int')\n",
    "        TF_prediction = pd.concat([TF_prediction, ranges], axis=1)\n",
    "    else:\n",
    "        TF_prediction = pd.read_csv(path, sep='\\t', header=None)\n",
    "        TF_prediction.columns = ['chrom','start','end', 'bound', 'TF']\n",
    "        TF_prediction['strand'] = '+'\n",
    "    # TF_prediction = TF_prediction.sort_values(by=['bound'], ascending=False) # sort such that bound = 1, comes first, and will be kept.\n",
    "    TF_prediction['summit'] = (TF_prediction['start']-1 + TF_prediction['end']) // 2\n",
    "    # TF_prediction = TF_prediction.drop_duplicates(['chrom','start', 'end'])\n",
    "    # TF_prediction = TF_prediction[TF_prediction['chrom'].isin(['chr1', 'chr3', 'chr6'])]\n",
    "    return TF_prediction\n",
    "\n",
    "def read_peaks(path):\n",
    "    df = pd.read_csv(path, sep='\\t', header=None)\n",
    "    df.columns = ['chrom', 'start', 'end']\n",
    "    print (df)\n",
    "    return df\n",
    "\n",
    "def get_normalization_factor(model, feat, peak, low=0.05, \n",
    "                             median = 0.5,\n",
    "                             high=0.95, sample_num=30000):\n",
    "    vs = []\n",
    "    with pyBigWig.open(f\"{model}/{feat}\", 'r') as f:\n",
    "        chroms = f.chroms().keys()\n",
    "        print (chroms)\n",
    "        peaks = peak[peak['chrom'].isin(chroms)].copy()\n",
    "        peaks['summit'] = (peaks['start'] + peaks['end']) // 2\n",
    "        peaks['start'] = peaks['summit'] - 400\n",
    "        peaks['end'] = peaks['summit'] + 400\n",
    "        if sample_num > 0:\n",
    "            peaks = peaks.sample(sample_num, replace=True).copy()\n",
    "        for chrom, start, end in zip(peaks['chrom'], peaks['start'], peaks['end']):\n",
    "            v = f.values(chrom, int(start), int(end), numpy=True)\n",
    "            vs.append(v)\n",
    "            \n",
    "    vs = np.concatenate(vs)\n",
    "    vs = np.nan_to_num(vs)\n",
    "    return np.quantile(vs, low), np.quantile(vs, median), np.quantile(vs, high)\n",
    "motifs = scp.motifs.Motifs(\"./human_pfms_v4.txt\", \n",
    "                           scp.genome.hg38.fetch_fa(), scp.genome.hg38.bg)\n",
    "motif2matrix = {motif.name.split(\"_\")[2]: np.array([motif.counts['A'], motif.counts['C'], motif.counts['G'], motif.counts['T']]) for motif in motifs.all_motifs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e250789-6e66-4422-93cb-7f6f4f49f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in motif2matrix:\n",
    "    mm = motif2matrix[m]\n",
    "    # print (mm.shape)\n",
    "    mm = mm / np.sum(mm, axis=0, keepdims=True)\n",
    "    motif2matrix[m] = mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8dcfb3b-0060-4a39-bf90-d6082a4ecf7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      chrom      start        end\n",
      "0      chr1     777315     778314\n",
      "1      chr1     778196     779195\n",
      "2      chr1     816901     817900\n",
      "3      chr1     826966     827965\n",
      "4      chr1     842352     843351\n",
      "...     ...        ...        ...\n",
      "81722  chrX  155880804  155881803\n",
      "81723  chrX  155986693  155987692\n",
      "81724  chrX  155997237  155998236\n",
      "81725  chrX  156001287  156002286\n",
      "81726  chrX  156006076  156007075\n",
      "\n",
      "[81727 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "tsvs = {cell:read_TF_loci(tsv_paths[cell]) for cell in tsv_paths}\n",
    "peaks = {cell:read_peaks(peaks_path[cell]) for cell in peaks_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71c487b2-2ffe-4bf8-9a51-53ad6e0f6a50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr2', 'chr20', 'chr21', 'chr22', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chrX'])"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089d2f2cf689443fb23e587730cac23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dict_keys(['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr2', 'chr20', 'chr21', 'chr22', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chrX'])\n",
      "dict_keys(['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr2', 'chr20', 'chr21', 'chr22', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chrX'])\n",
      "dict_keys(['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr2', 'chr20', 'chr21', 'chr22', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chrX'])\n",
      "dict_keys(['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr2', 'chr20', 'chr21', 'chr22', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chrX'])\n",
      "dict_keys(['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr2', 'chr20', 'chr21', 'chr22', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chrX'])\n",
      "dict_keys(['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr2', 'chr20', 'chr21', 'chr22', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chrX'])\n",
      "dict_keys(['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr2', 'chr20', 'chr21', 'chr22', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chrX'])\n",
      "dict_keys(['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr2', 'chr20', 'chr21', 'chr22', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chrX'])\n",
      "dict_keys(['chr1', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr2', 'chr20', 'chr21', 'chr22', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chrX'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pool= ProcessPoolExecutor(max_workers=100)\n",
    "norm_factor = {}\n",
    "p_list = []\n",
    "for cell in model_name:\n",
    "    norm_factor[cell] = {}\n",
    "    for feat in feats:\n",
    "        norm_factor[cell][feat] = []\n",
    "        for model in model_name[cell]:\n",
    "            p = pool.submit(get_normalization_factor,model, \n",
    "                                                   feat,\n",
    "                                                   peaks[cell], sample_num=-1)\n",
    "            norm_factor[cell][feat].append(p)\n",
    "            p_list.append(p)\n",
    "for p in tqdm(as_completed(p_list), total=len(p_list)):\n",
    "    continue\n",
    "for cell in model_name:\n",
    "    for feat in feats:\n",
    "        for i, model in enumerate(model_name[cell]):\n",
    "            norm_factor[cell][feat][i] = norm_factor[cell][feat][i].result()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d013ab7-3bc9-48a6-accd-bb854f50987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K562 attr.count.shap_hypo_0_.0.85.bigwig 0 0.00 1.20\n",
      "K562 attr.count.shap_hypo_0_.0.85.bigwig 1 0.00 1.23\n",
      "K562 attr.count.shap_hypo_0_.0.85.bigwig 2 0.00 1.22\n",
      "K562 attr.count.shap_hypo_0_.0.85.bigwig 3 0.00 1.20\n",
      "K562 attr.count.shap_hypo_0_.0.85.bigwig 4 0.00 1.21\n",
      "K562 attr.just_sum.shap_hypo_0-30_.0.85.bigwig 0 0.00 1.18\n",
      "K562 attr.just_sum.shap_hypo_0-30_.0.85.bigwig 1 0.00 1.16\n",
      "K562 attr.just_sum.shap_hypo_0-30_.0.85.bigwig 2 0.00 1.16\n",
      "K562 attr.just_sum.shap_hypo_0-30_.0.85.bigwig 3 0.00 1.18\n",
      "K562 attr.just_sum.shap_hypo_0-30_.0.85.bigwig 4 0.00 1.18\n"
     ]
    }
   ],
   "source": [
    "for cell in model_name:\n",
    "    for feat in feats:\n",
    "        for i, model in enumerate(model_name[cell]):\n",
    "            lo, mid,hi = norm_factor[cell][feat][i]\n",
    "            print (cell, feat, i, \"%.2f\" % mid, \"%.2f\"%(hi-lo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88317e50-9bb2-43bf-9bff-2162e880dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfaidx import Fasta\n",
    "from scipy.stats import *\n",
    "def cosine(x,y):\n",
    "    return (x*y).sum() / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "    # return spearmanr(x, y)[0]\n",
    "def get_feats(model, feat, tsv,\n",
    "              flank,\n",
    "              low=None, median=None, high=None, chroms = None,\n",
    "             verbose=False):\n",
    "    if low is None:\n",
    "        low = 0\n",
    "        median = 0\n",
    "        high = 1\n",
    "    fasta = Fasta(scp.genome.hg38.fetch_fa())\n",
    "    signals = []\n",
    "    similarity = []\n",
    "    strengths = []\n",
    "    with pyBigWig.open(f\"{model}/{feat}\", 'r') as f:\n",
    "        if chroms is None:\n",
    "            chroms = f.chroms().keys()\n",
    "        tsv = tsv[tsv['chrom'].isin(chroms)].copy()\n",
    "        chrom, summit, strand = np.array(tsv['chrom']), np.array(tsv['summit']), np.array(tsv['strand'])\n",
    "        starts, ends, strands = np.array(tsv['start']), np.array(tsv['end']), np.array(tsv['strand'])\n",
    "        tfs = np.array(tsv['TF'])\n",
    "        labels = np.array(tsv['bound'])\n",
    "\n",
    "        \n",
    "        for c,s,sd,tf, start,end in zip(tqdm(chrom, disable=not verbose), summit, strands, tfs, starts, ends):\n",
    "            \n",
    "            try:\n",
    "                v = f.values(c, s-flank, s+flank+1, numpy=True)\n",
    "            except:\n",
    "                print (c, s-flank, s+flank+1)\n",
    "                v = np.zeros((int(2*flank+1)))\n",
    "            if sd != '+':\n",
    "                v = v[::-1]\n",
    "\n",
    "            # seq = hg38.fetch_onehot_seq(c, start-1, end).numpy()\n",
    "            seq = fasta[c][start-1:end].seq\n",
    "            seq = scp.utils.DNA_one_hot(seq).numpy()\n",
    "            seq_trend = f.values(c, start-1, end, numpy=True)\n",
    "            if sd == '-':\n",
    "                seq = seq[::-1][:, ::-1]\n",
    "                seq_trend = seq_trend[::-1]\n",
    "            motif_trend = (motif2matrix[tf] * seq).sum(axis=0)\n",
    "            motif_match = cosine(motif2matrix[tf].reshape((-1)), seq.reshape((-1)))\n",
    "            \n",
    "            signals.append(v)\n",
    "            similarity.append([cosine(seq_trend, motif_trend), \n",
    "                               # motif_match,\n",
    "                               ((seq_trend - median) / (high - low)).mean()])\n",
    "    \n",
    "    signals = np.array(signals)\n",
    "    similarity = np.array(similarity)\n",
    "    signals = np.nan_to_num(signals)\n",
    "    similarity =  np.nan_to_num(similarity)\n",
    "\n",
    "    # for tf in np.unique(tfs):\n",
    "    #     mask = tfs == tf\n",
    "    #     v = similarity[mask]\n",
    "    #     v = (v - np.min(v, axis=0, keepdims=True)) / (np.max(v, axis=0, keepdims=True) - np.min(v, axis=0, keepdims=True))\n",
    "    #     similarity[mask] = v\n",
    "\n",
    "    \n",
    "    signals = (signals - median) / (high - low)\n",
    "    return signals, similarity, tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40f28fc2-80cb-47ef-adec-4378b4d135d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213d2a4f43b94bf7b7128a3c2e6e8889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feats_all = {}\n",
    "labels_all = {}\n",
    "pool= ProcessPoolExecutor(max_workers=200)\n",
    "p_list = []\n",
    "for cell in model_name:\n",
    "    for feat in feats:\n",
    "        for i, model in enumerate(model_name[cell]):\n",
    "            # lo, mid, hi = norm_factor[cell][feat][i]\n",
    "            # lo, mid, hi = 0,0,1\n",
    "            lo, mid, hi = None, None, None\n",
    "            p_list.append(pool.submit(get_feats,model, feat, tsvs[cell], \n",
    "                  100,\n",
    "                  lo, mid, hi))\n",
    "\n",
    "for p in tqdm(as_completed(p_list), total=len(p_list)):\n",
    "    continue\n",
    "ct = 0\n",
    "for cell in model_name:\n",
    "    feats_cell = []\n",
    "    sims_cell = []\n",
    "    for feat in feats:\n",
    "        feats_v = 0\n",
    "        sims_v = 0\n",
    "        for i, model in enumerate(model_name[cell]):\n",
    "            feats_, sims_, labels = p_list[ct].result()\n",
    "            ct += 1\n",
    "            feats_v += feats_\n",
    "            sims_v += sims_\n",
    "        feats_v = feats_v / len(model_name[cell])\n",
    "        sims_v = sims_v / len(model_name[cell])\n",
    "        feats_cell.append(feats_v)\n",
    "        sims_cell.append(sims_v)\n",
    "    feats_cell = np.stack(feats_cell, axis=1)\n",
    "    sims_cell = np.stack(sims_cell, axis=1)\n",
    "    # print (feats_cell.shape, sims_cell.shape)\n",
    "    feats_all[cell] = [feats_cell, sims_cell]\n",
    "    labels_all[cell] = labels\n",
    "pool.shutdown(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b91b90-ceac-4d26-a143-5f0dc59488a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "hepg2_train, hepg2_val = train_test_split(np.arange(len(labels_all['HepG2_0'])), test_size=0.1, random_state=42)\n",
    "gm_train, gm_val = train_test_split(np.arange(len(labels_all['GM12878_0'])), test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbcddcdf-34fb-40a2-b59d-75a748928c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cells_hepg2 = ['HepG2_0', \n",
    "             'HepG2_1', \n",
    "             'HepG2_2', \n",
    "             'HepG2_3', \n",
    "             'HepG2_4'\n",
    "                    ]\n",
    "train_cells_gm12878 = ['GM12878_0',\n",
    "             'GM12878_1',\n",
    "             'GM12878_2',\n",
    "             'GM12878_3',\n",
    "             'GM12878_4'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8d2055b-71b9-44bd-a228-9d952161deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feats_for_cell(feats_all, labels_all, cell, window=201, n_feats=np.arange(8)):\n",
    "    seq_attr = feats_all[cell][0]\n",
    "    pad = (seq_attr.shape[-1] - window) // 2\n",
    "    if pad > 0:\n",
    "        seq_attr = seq_attr[..., pad:-pad]\n",
    "    # seq_attr = seq_attr[:, n_feats].reshape((len(seq_attr), -1))\n",
    "    seq_motif_sim = feats_all[cell][1][:, n_feats]\n",
    "    motifs = np.asarray(labels_all[cell]['motifMatchScore'])[:, None]\n",
    "    motifs = np.stack([motifs] * len(n_feats), axis=1)\n",
    "    # feats = seq_motif_sim.reshape((len(seq_attr), -1))\n",
    "    feats = np.concatenate([motifs, seq_motif_sim, seq_attr], axis=-1)\n",
    "    print (motifs.shape, seq_motif_sim.shape, seq_attr.shape)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c55a46-770a-4268-acad-cc0af05073a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = np.concatenate([feats_for_cell(feats_all, labels_all, cell,n_feats=np.arange(2))[hepg2_train] for cell in train_cells_hepg2] + \n",
    "                            [feats_for_cell(feats_all, labels_all, cell,n_feats=np.arange(2))[gm_train] for cell in train_cells_gm12878], axis=0)\n",
    "\n",
    "valid_feats = np.concatenate([feats_for_cell(feats_all, labels_all, cell,n_feats=np.arange(2))[hepg2_val] for cell in train_cells_hepg2] + \n",
    "                            [feats_for_cell(feats_all, labels_all, cell,n_feats=np.arange(2))[gm_val] for cell in train_cells_gm12878], axis=0)\n",
    "\n",
    "train_labels = np.concatenate([np.asarray(labels_all[cell]['bound'])[hepg2_train] for cell in train_cells_hepg2] + \n",
    "[np.asarray(labels_all[cell]['bound'])[gm_train] for cell in train_cells_gm12878], axis=0)\n",
    "valid_labels = np.concatenate([np.asarray(labels_all[cell]['bound'])[hepg2_val] for cell in train_cells_hepg2] + [np.asarray(labels_all[cell]['bound'])[gm_val] for cell in train_cells_gm12878], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "042bbbdf-a2a7-47de-9220-b489d700918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump([train_feats, valid_feats, train_labels, valid_labels], open(\"finetune_TFBS.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96258f0c-3a9a-4f5b-b2a9-b817b761fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = np.concatenate(\n",
    "                            [feats_for_cell(feats_all, labels_all, cell,n_feats=np.arange(2))[gm_train] for cell in train_cells_gm12878], axis=0)\n",
    "\n",
    "valid_feats = np.concatenate(\n",
    "                            [feats_for_cell(feats_all, labels_all, cell,n_feats=np.arange(2))[gm_val] for cell in train_cells_gm12878], axis=0)\n",
    "\n",
    "train_labels = np.concatenate(\n",
    "[np.asarray(labels_all[cell]['bound'])[gm_train] for cell in train_cells_gm12878], axis=0)\n",
    "valid_labels = np.concatenate([np.asarray(labels_all[cell]['bound'])[gm_val] for cell in train_cells_gm12878], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1791f8cc-2f09-4e5f-b454-65473119f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump([train_feats, valid_feats, train_labels, valid_labels], open(\"finetune_TFBS_GM.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1b93c6-68a5-4c51-bb53-474bab40935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "# Validation step with AUPR reporting\n",
    "def validate_model(model, val_loader, criterion, device=\"cpu\"):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # No need to compute gradient when evaluating\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)[..., 0, :]\n",
    "            val_loss += criterion(outputs, labels.float()).item()\n",
    "\n",
    "            # # Store predictions and labels\n",
    "            all_preds.extend(torch.sigmoid(outputs).cpu().numpy())  # Assuming binary classification\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_loss *= 100\n",
    "    val_aupr = average_precision_score(all_labels, all_preds)  # Compute AUPR\n",
    "    return val_loss, val_aupr\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from scprinter.backup.ema import EMA\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = nn.functional.cross_entropy(inputs, targets, reduction=\"none\")\n",
    "        else:\n",
    "            BCE_loss = nn.functional.binary_cross_entropy_with_logits(\n",
    "                inputs, targets, reduction=\"none\"\n",
    "            )\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "\n",
    "# 1. Define the MLP Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, input_channel, mean, scale):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mean = nn.Parameter(torch.from_numpy(mean).float())\n",
    "        self.scale = nn.Parameter(torch.from_numpy(scale).float())\n",
    "        self.fc1 = nn.Linear((input_size) * input_channel, 256)  # First hidden layer\n",
    "        self.activation1 = nn.GELU()\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(256, 128)  # Second hidden layer\n",
    "        self.activation2 = nn.GELU()\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.fc3 = nn.Linear(128, 64)  # Output layer, assuming 10 classes\n",
    "        self.activation3 = nn.GELU()\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        self.fc4 = nn.Linear(64, 1)  # Output layer, assuming 10 classes\n",
    "\n",
    "        # self.fc5 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = (x - self.mean[-x.shape[-1] :]) / self.scale[-x.shape[-1] :]\n",
    "        xx = self.dropout1(self.activation1(self.fc1(x[..., :].reshape(x.shape[0], -1))))\n",
    "        xx = self.dropout2(self.activation2(self.fc2(xx)))\n",
    "        xx = self.dropout3(self.activation3(self.fc3(xx)))\n",
    "        xx = self.fc4(xx)  # No activation, will use nn.CrossEntropyLoss\n",
    "        # xx = xx + self.fc5(x[..., :3].mean(dim=1))\n",
    "        return xx\n",
    "\n",
    "\n",
    "class TFConv(nn.Module):\n",
    "    def __init__(self, input_size, input_channel, mean, scale):\n",
    "        super(TFConv, self).__init__()\n",
    "        self.mean = nn.Parameter(torch.from_numpy(mean).float())\n",
    "        self.scale = nn.Parameter(torch.from_numpy(scale).float())\n",
    "        self.mean.requires_grad = False\n",
    "        self.scale.requires_grad = False\n",
    "        self.input_size = input_size\n",
    "        self.input_channel = input_channel\n",
    "\n",
    "        self.conv1 = nn.Conv1d(input_channel, 256, input_size)\n",
    "        self.activation1 = nn.GELU()\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.conv2 = nn.Conv1d(256, 128, 1)\n",
    "        self.activation2 = nn.GELU()\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.conv3 = nn.Conv1d(128, 64, 1)\n",
    "        self.activation3 = nn.GELU()\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        self.conv4 = nn.Conv1d(64, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if x.shape[-1] != self.mean.shape[-1]:\n",
    "            x = (x - self.mean[3:]) / self.scale[3:]\n",
    "            x = torch.cat(\n",
    "                [\n",
    "                    torch.zeros([x.shape[0], x.shape[1], 3], device=x.device, dtype=x.dtype),\n",
    "                    x,\n",
    "                ],\n",
    "                dim=2,\n",
    "            )\n",
    "        else:\n",
    "            x = (x - self.mean) / self.scale\n",
    "        # x = (x - self.mean) / self.scale\n",
    "        xx = self.dropout1(self.activation1(self.conv1(x)))\n",
    "        xx = self.dropout2(self.activation2(self.conv2(xx)))\n",
    "        xx = self.dropout3(self.activation3(self.conv3(xx)))\n",
    "        xx = self.conv4(xx)\n",
    "        return xx\n",
    "\n",
    "\n",
    "class TFConv_translate(nn.Module):\n",
    "    def __init__(self, tfconv):\n",
    "        super(TFConv_translate, self).__init__()\n",
    "        # self = deepcopy(tfconv)\n",
    "        print(\n",
    "            tfconv.conv1.weight.shape,\n",
    "            tfconv.conv1.bias.shape,\n",
    "            tfconv.mean.shape,\n",
    "            tfconv.scale.shape,\n",
    "        )\n",
    "        new_weight_0 = 1 / tfconv.scale[None] * tfconv.conv1.weight[:, 0, :]\n",
    "        new_weight_1 = (\n",
    "            tfconv.conv1.bias - (tfconv.mean / tfconv.scale) @ tfconv.conv1.weight[:, 0, :].T\n",
    "        )\n",
    "        print(new_weight_0.shape, new_weight_1.shape)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(tfconv.input_channel, 256, tfconv.input_size)\n",
    "        self.activation1 = nn.GELU()\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.conv2 = nn.Conv1d(256, 128, 1)\n",
    "        self.activation2 = nn.GELU()\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.conv3 = nn.Conv1d(128, 64, 1)\n",
    "        self.activation3 = nn.GELU()\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        self.conv4 = nn.Conv1d(64, 1, 1)\n",
    "\n",
    "        self.conv1.weight.data = new_weight_0[:, None, :]\n",
    "        self.conv1.bias.data = new_weight_1\n",
    "        self.with_motif = True\n",
    "        self.conv2.weight.data = tfconv.conv2.weight.data\n",
    "        self.conv2.bias.data = tfconv.conv2.bias.data\n",
    "        self.conv3.weight.data = tfconv.conv3.weight.data\n",
    "        self.conv3.bias.data = tfconv.conv3.bias.data\n",
    "        self.conv4.weight.data = tfconv.conv4.weight.data\n",
    "        self.conv4.bias.data = tfconv.conv4.bias.data\n",
    "\n",
    "    def with_motif(self, flag):\n",
    "        self.with_motif = flag\n",
    "\n",
    "    def forward(self, x):\n",
    "        # if not self.with_motif:\n",
    "        #     x = F.conv1d(x, self.conv1.weight[:, :, 3:], self.conv1.bias)\n",
    "        # else:\n",
    "        x = F.conv1d(x, self.conv1.weight, self.conv1.bias)\n",
    "\n",
    "        xx = self.dropout1(self.activation1(x))\n",
    "        xx = self.dropout2(self.activation2(self.conv2(xx)))\n",
    "        xx = self.dropout3(self.activation3(self.conv3(xx)))\n",
    "        xx = self.conv4(xx)\n",
    "        return xx\n",
    "\n",
    "\n",
    "# The model is now trained, you\\ can save it or further evaluate it.\n",
    "\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "\n",
    "for feats in [[0], [1]]:\n",
    "    feats = np.array(feats)\n",
    "    \n",
    "    train_feats, valid_feats, train_labels, valid_labels = pickle.load(open(\"finetune_TFBS.pkl\", \"rb\"))\n",
    "    train_feats = train_feats[:, feats, 3:]\n",
    "    train_shape = train_feats.shape\n",
    "    train_feats = train_feats.reshape((len(train_feats), len(feats), -1))\n",
    "    valid_feats = valid_feats[:, feats, 3:]\n",
    "    valid_shape = valid_feats.shape\n",
    "    valid_feats = valid_feats.reshape((len(valid_feats), len(feats), -1))\n",
    "    \n",
    "    \n",
    "    from sklearn.preprocessing import *\n",
    "    \n",
    "    scaler = StandardScaler().fit(train_feats[:, 0, :])\n",
    "    mean, std = scaler.mean_, scaler.scale_\n",
    "    \n",
    "    \n",
    "    X_train = torch.as_tensor(train_feats).float()  # [:, 0, :]\n",
    "    y_train = torch.as_tensor(train_labels[:, None]).long()\n",
    "    X_val = torch.as_tensor(valid_feats).float()  # [:, 0, :]\n",
    "    y_val = torch.as_tensor(valid_labels[:, None]).long()\n",
    "    \n",
    "    print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "    \n",
    "    class_counts = y_train.sum()\n",
    "    class_counts = torch.as_tensor([(class_counts) / len(y_train)])\n",
    "    class_weights = 1.0 / class_counts.float()\n",
    "    # Create DataLoader instances\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    \n",
    "    batch_size = 512  # You can adjust the batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Initialize the MLP\n",
    "    model = TFConv(X_train.shape[-1], X_train.shape[-2], mean, std).cuda()\n",
    "    ema = EMA(\n",
    "        model,\n",
    "        beta=0.9999,  # exponential moving average factor\n",
    "        update_after_step=100,  # only after this number of .update() calls will it start updating\n",
    "        update_every=1,\n",
    "    ).cuda()\n",
    "    # 3. Training Loop\n",
    "    criterion = nn.BCEWithLogitsLoss(weight=class_weights.cuda())\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4)  # Learning rate can be adjusted\n",
    "    \n",
    "    num_epochs = 1000  # Number of epochs can be adjusted\n",
    "    val_freq = 1000\n",
    "    best_val_loss = 0\n",
    "    no_improv_thres = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        ct = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            optimizer.zero_grad()  # Zero the parameter gradients\n",
    "            outputs = model(inputs)[..., 0, :]  # Forward pass\n",
    "            loss = criterion(outputs, labels.float())  # Compute the loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Optimize\n",
    "            ema.update()\n",
    "            ct += 1\n",
    "            if ct >= val_freq:\n",
    "                ct = 0\n",
    "                break\n",
    "    \n",
    "        # 4. Validation Step\n",
    "        m = ema.ema_model\n",
    "        val_loss, val_aupr = validate_model(m, val_loader, criterion, \"cuda\")\n",
    "        print(f\"Epoch: {epoch + 1}, Validation Loss: {val_loss:.4f}, Validation AUPR: {val_aupr:.4f}\")\n",
    "        if val_aupr > best_val_loss:\n",
    "            best_val_loss = val_aupr\n",
    "            no_improv = 0\n",
    "        else:\n",
    "            no_improv += 1\n",
    "    \n",
    "        if no_improv >= no_improv_thres:\n",
    "            break\n",
    "        model.train()\n",
    "        ema.train()\n",
    "    m2 = TFConv_translate(m)\n",
    "    print(m2)\n",
    "    m = m.eval()\n",
    "    m2 = m2.eval()\n",
    "    a, b = m(inputs), m2(inputs)\n",
    "    print(\n",
    "        a.shape, b.shape, a.reshape((-1)), b.reshape((-1)), torch.allclose(a, b, atol=1e-3, rtol=1e-3)\n",
    "    )\n",
    "    from scipy.stats import pearsonr\n",
    "    \n",
    "    print(pearsonr(a.reshape((-1)).cpu().detach().numpy(), b.reshape((-1)).cpu().detach().numpy()))\n",
    "    m2 = torch.jit.script(m2)\n",
    "    # Save to file\n",
    "    torch.jit.save(m2, f\"TFBS_{feats[0]}_conv_v2.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05155bf-16dc-485a-bece-f51360410f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74d909-b0da-492c-a60e-3ad7dcb701b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aef270-8f78-4758-8466-c1c32ec8295e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f9baf84-3abd-46d3-9d44-1f9d81c0b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "scaler = StandardScaler().fit(train_feats.reshape((len(train_feats), -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1193e9-19fe-4593-8ca2-a9ed29a47c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(scaler, open(\"TFBS_scaler.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e37adae4-0ed2-49a4-82bc-3fc8c844e052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to unpickle estimator StandardScaler from version 1.4.0 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "scaler = pickle.load(open(\"TFBS_scaler.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5275b60c-4169-4ca8-bc6a-9c35e06036ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfaidx import Fasta\n",
    "from scipy.stats import *\n",
    "def fill_in_baseline(bw_path, name, tsv,\n",
    "             chroms = None,\n",
    "             verbose=False):\n",
    "    fasta = Fasta(scp.genome.hg38.fetch_fa())\n",
    "    signals = []\n",
    "    with pyBigWig.open(f\"{bw_path}\", 'r') as f:\n",
    "        if chroms is None:\n",
    "            chroms = f.chroms().keys()\n",
    "        tsv = tsv[tsv['chrom'].isin(chroms)].copy()\n",
    "        chrom, summit, strand = np.array(tsv['chrom']), np.array(tsv['summit']), np.array(tsv['strand'])\n",
    "        starts, ends, strands = np.array(tsv['start']), np.array(tsv['end']), np.array(tsv['strand'])\n",
    "        \n",
    "        \n",
    "        for c,s,sd, start,end in zip(tqdm(chrom, disable=not verbose), summit, strands, starts, ends):\n",
    "            v = f.values(c, start, end, numpy=True)\n",
    "            # print (v)\n",
    "            v = np.nanmean(v)\n",
    "            \n",
    "            signals.append(v)\n",
    "            \n",
    "    signals = np.array(signals)\n",
    "    signals = np.nan_to_num(signals)\n",
    "    tsv[name] = signals\n",
    "    return tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "995b0420-c705-430d-9de5-afb218a67f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_832523/703955188.py:19: RuntimeWarning: Mean of empty slice\n",
      "/tmp/ipykernel_832523/703955188.py:19: RuntimeWarning: Mean of empty slice\n",
      "/tmp/ipykernel_832523/703955188.py:19: RuntimeWarning: Mean of empty slice\n",
      "/tmp/ipykernel_832523/703955188.py:19: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "tsvs['K562'] = fill_in_baseline('/data/rzhang/PRINT_rev/K562/K562_footprints_hg38.bw.bw',\n",
    "                                'TOBIAS', tsvs['K562'])\n",
    "tsvs['K562'] = fill_in_baseline('/data/rzhang/PRINT_rev/K562/chrombp/k562_rep1.counts_scores.bw',\n",
    "                                'chromBPNet', tsvs['K562'])\n",
    "tsvs['K562'] = fill_in_baseline('/data/rzhang/PRINT_rev/vierstra/interval.all.winlnpval.K562-DS15363.bw',\n",
    "                                'DS15363', tsvs['K562'])\n",
    "tsvs['K562'] = fill_in_baseline('/data/rzhang/PRINT_rev/vierstra/interval.all.winlnpval.K562-DS16924.bw',\n",
    "                                'DS16924', tsvs['K562'])\n",
    "tsvs['K562'] = fill_in_baseline('/data/rzhang/PRINT_rev/vierstra/interval.all.winlnpval.h.K562-DS52908.bw',\n",
    "                                'DS52908', tsvs['K562'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14353721-ea09-4b09-9319-039a1c78c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(feats_all, labels_all, \n",
    "               clf_mega, \n",
    "               cell, \n",
    "               window=201, \n",
    "               n_feats=3, \n",
    "               feat_mask = None, \n",
    "               scaler=None):\n",
    "    from sklearn.metrics import average_precision_score\n",
    "    feats = feats_for_cell(feats_all, \n",
    "                                           labels_all, \n",
    "                                           cell, \n",
    "                                           window=window, \n",
    "                                           n_feats=np.arange(n_feats))\n",
    "    tsv = labels_all[cell]\n",
    "    shape = feats.shape\n",
    "    print (feats.shape)\n",
    "    print (feats[:, :, 1].min(), feats[:, :, 1].max())\n",
    "   \n",
    "    pred_all = 0\n",
    "    for i, model in enumerate(clf_mega):\n",
    "        pred = torch.sigmoid(model(torch.from_numpy(feats)[:, i:i+1, :].float())).detach().cpu().numpy()[:, 0, :] #+\\\n",
    "        pred_all += pred\n",
    "        tsv[f'pred_{i}'] = pred\n",
    "    pred_all /= len(clf_mega)\n",
    "    tsv['pred'] = pred_all\n",
    "    return tsv\n",
    "    \n",
    "def summarize(tsv, col='pred', tf_subset=None):\n",
    "    from sklearn.metrics import average_precision_score\n",
    "\n",
    "    precisions = []\n",
    "    auprs = []\n",
    "    tfs = []\n",
    "    sig = tsv.copy()\n",
    "    if tf_subset is None:\n",
    "        tf_subset = sig['TF'].unique()\n",
    "    tf_subset = set(tf_subset) & set(sig['TF'].unique())\n",
    "    \n",
    "    sig = sig[sig['TF'].isin(tf_subset)]\n",
    "    if len(tf_subset) == 0:\n",
    "        return 0\n",
    "    summary = sig.groupby('TF')\n",
    "    score1 = average_precision_score(sig['bound'], sig[col])\n",
    "    tf_subset = np.sort(list(tf_subset))\n",
    "    for tf in tf_subset:\n",
    "        sig = summary.get_group(tf)\n",
    "        v = np.array(sig[col])\n",
    "        label = np.array(sig['bound'])\n",
    "        top10pct = np.mean(label[v >= np.quantile(v, 0.9)])\n",
    "        aupr = average_precision_score(sig['bound'], sig[col])\n",
    "        precisions.append(top10pct)\n",
    "        auprs.append(aupr)\n",
    "        tfs.append(tf)\n",
    "    summary_performance = pd.DataFrame({'tf':tfs, 'precision': precisions, 'aupr':auprs})\n",
    "    return summary_performance, score1, summary_performance['precision'].mean(), summary_performance['precision'].median(), summary_performance['aupr'].mean(), summary_performance['aupr'].median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30254c28-cc36-48cf-8bc3-28d4088ae72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "models = [torch.jit.load(f\"TFBS_{i}_conv_v2.pt\", map_location='cpu').eval() for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10cdde03-9470-4c07-87ee-388293eab9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    m.with_motifs=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6a04196-c906-4960-8d77-b63ed7d6ebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_class = '/data/rzhang/PRINT_rev/HepG2/cluster_supp.txt'\n",
    "TF_class = pd.read_csv(TF_class, sep='\\t')\n",
    "TF_class.index = TF_class['TF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5c11181-45f2-436a-b7d6-177b7f57d567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ATF2</th>\n",
       "      <td>ATF2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHLHE40</th>\n",
       "      <td>BHLHE40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEBPB</th>\n",
       "      <td>CEBPB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEBPG</th>\n",
       "      <td>CEBPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREB1</th>\n",
       "      <td>CREB1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREM</th>\n",
       "      <td>CREM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTCF</th>\n",
       "      <td>CTCF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTCFL</th>\n",
       "      <td>CTCFL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGR1</th>\n",
       "      <td>EGR1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MITF</th>\n",
       "      <td>MITF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFIA</th>\n",
       "      <td>NFIA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFIC</th>\n",
       "      <td>NFIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR2F1</th>\n",
       "      <td>NR2F1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR2F6</th>\n",
       "      <td>NR2F6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NRF1</th>\n",
       "      <td>NRF1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USF1</th>\n",
       "      <td>USF1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USF2</th>\n",
       "      <td>USF2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOS</th>\n",
       "      <td>FOS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOSL1</th>\n",
       "      <td>FOSL1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GABPA</th>\n",
       "      <td>GABPA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JUNB</th>\n",
       "      <td>JUNB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAFF</th>\n",
       "      <td>MAFF</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAFK</th>\n",
       "      <td>MAFK</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAX</th>\n",
       "      <td>MAX</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MXI1</th>\n",
       "      <td>MXI1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MYC</th>\n",
       "      <td>MYC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFE2L2</th>\n",
       "      <td>NFE2L2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR2F2</th>\n",
       "      <td>NR2F2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFX1</th>\n",
       "      <td>RFX1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAL1</th>\n",
       "      <td>TAL1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELF1</th>\n",
       "      <td>ELF1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOXK2</th>\n",
       "      <td>FOXK2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JUN</th>\n",
       "      <td>JUN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JUND</th>\n",
       "      <td>JUND</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELF4</th>\n",
       "      <td>ELF4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELK1</th>\n",
       "      <td>ELK1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HMBOX1</th>\n",
       "      <td>HMBOX1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IRF2</th>\n",
       "      <td>IRF2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFYA</th>\n",
       "      <td>NFYA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFYB</th>\n",
       "      <td>NFYB</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YY1</th>\n",
       "      <td>YY1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TF  cluster\n",
       "TF                       \n",
       "ATF2        ATF2        1\n",
       "BHLHE40  BHLHE40        1\n",
       "CEBPB      CEBPB        1\n",
       "CEBPG      CEBPG        1\n",
       "CREB1      CREB1        1\n",
       "CREM        CREM        1\n",
       "CTCF        CTCF        1\n",
       "CTCFL      CTCFL        1\n",
       "EGR1        EGR1        1\n",
       "MITF        MITF        1\n",
       "NFIA        NFIA        1\n",
       "NFIC        NFIC        1\n",
       "NR2F1      NR2F1        1\n",
       "NR2F6      NR2F6        1\n",
       "NRF1        NRF1        1\n",
       "USF1        USF1        1\n",
       "USF2        USF2        1\n",
       "FOS          FOS        2\n",
       "FOSL1      FOSL1        2\n",
       "GABPA      GABPA        2\n",
       "JUNB        JUNB        2\n",
       "MAFF        MAFF        2\n",
       "MAFK        MAFK        2\n",
       "MAX          MAX        2\n",
       "MXI1        MXI1        2\n",
       "MYC          MYC        2\n",
       "NFE2L2    NFE2L2        2\n",
       "NR2F2      NR2F2        2\n",
       "RFX1        RFX1        2\n",
       "TAL1        TAL1        2\n",
       "ELF1        ELF1        3\n",
       "FOXK2      FOXK2        3\n",
       "JUN          JUN        3\n",
       "JUND        JUND        3\n",
       "ELF4        ELF4        4\n",
       "ELK1        ELK1        4\n",
       "HMBOX1    HMBOX1        4\n",
       "IRF2        IRF2        4\n",
       "NFYA        NFYA        4\n",
       "NFYB        NFYB        4\n",
       "YY1          YY1        4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c959b8-e21f-476b-b845-6a4b7bd18315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "score = eval_model(feats_all, labels_all, models, 'K562',201, 2)\n",
    "col = 'pred'\n",
    "print (summarize(score, col))\n",
    "dfs = []\n",
    "for i in range(1, 5):\n",
    "    a, _, _, _, _, _ =  summarize(score,col, TF_class[TF_class['cluster'] == i].index)\n",
    "    print (col, i, np.median(a['precision']))\n",
    "    dfs.append(a)\n",
    "dfs = pd.concat(dfs, axis=0)\n",
    "dfs_pred = dfs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1eb0f8c0-b198-46ec-b928-ec8d304cabfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5626043405676127\n",
      "0.6201329534662868\n",
      "0.5841584158415841\n",
      "0.5791015625\n",
      "0.5795868772782503\n",
      "0.6423017107309487\n"
     ]
    }
   ],
   "source": [
    "for col in ['TOBIAS','chromBPNet','DS15363','DS16924','DS52908', 'predScore']:\n",
    "    dff = tsvs['K562']\n",
    "    # col = 'motifMatchScore'\n",
    "    print (summarize(dff, col)[3])\n",
    "    dfs = []\n",
    "    for i in range(1, 5):\n",
    "        a, _, _, _, _, _ = summarize(dff,col, TF_class[TF_class['cluster'] == i].index)\n",
    "        dfs.append(a)\n",
    "    dfs = pd.concat(dfs, axis=0)\n",
    "    dfs.to_csv(f'/data/rzhang/PRINT_rev/K562/{col}_perform.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5b42280-38ee-4ebb-8b1b-dc2f4f67d009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=x,y=y, hue=color,  data=results_sorted, width=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a7decf-0406-4c1d-8684-0d58a192ed8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f0402-d25f-469d-b322-42f3b2d68e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

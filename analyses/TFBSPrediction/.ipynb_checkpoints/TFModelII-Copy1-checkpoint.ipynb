{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b226516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pickle\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K    \n",
    "from sklearn.metrics import roc_auc_score as auroc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2990aac",
   "metadata": {},
   "source": [
    "### Load multi-scale footprint and TF binding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca9a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we train a model that takes each genomic site with a matched TF motif\n",
    "# and predicts whether the site is bound by the corresponding TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08263bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7705e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFBS_data = []\n",
    "binding_labels = []\n",
    "TF_labels = []\n",
    "datasets = [\"HepG2\", \"GM12878\"]\n",
    "for dataset in datasets:\n",
    "\n",
    "    hf = h5py.File(\"../../data/\" + dataset + \"/TFBSDataUnibind.h5\", 'r')\n",
    "\n",
    "    # Multi-scale footprint scores for each TF motif site\n",
    "    # Here we use footprints calculated using 6 different window sizes:\n",
    "    # 10bp, 20bp, 30bp, 50bp, 80bp, 100bp (radius, not diameter)\n",
    "    # For each window radius, we take a 201 bp (+/- 100bp with the motif center 1bp) local neighborhood \n",
    "    # as model input. Therefore for each locus we have a 201 * 6 = 1206 dimensional vector as input\n",
    "    # If we have in total N motif matched sites, then hf['motifFootprints'] should be a N-by-1026 matrix\n",
    "    footprints = hf['motifFootprints']\n",
    "    footprints = np.transpose(np.array(footprints))\n",
    "\n",
    "    # Metadata of each motif site\n",
    "    metadata = hf['metadata']\n",
    "    metadata = np.array(metadata)\n",
    "\n",
    "    # Ground truth TF binding label. An array of 0s (unbound) and 1s (bound).\n",
    "    TF_bound = np.array([i[0] for i in metadata])\n",
    "\n",
    "    # Motif match scores. Describe how well a motif is matched\n",
    "    motif_score = np.array([i[1] for i in metadata])\n",
    "\n",
    "    # The corresponding TF names for each motif site\n",
    "    TF_labels.append(np.array([i[2].decode('ascii') for i in metadata]))\n",
    "\n",
    "    # Combine all non-footprint features as additional features\n",
    "    motif_score = np.reshape(motif_score, (-1, 1))\n",
    "    TFBS_data.append(np.concatenate([footprints, motif_score], axis = 1))\n",
    "    binding_labels.append(TF_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee882196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data from each dataset\n",
    "dataset_label = np.concatenate([[datasets[i] for j in range(len(TF_labels[i]))] for i in range(len(datasets))])\n",
    "TFBS_data = np.concatenate(TFBS_data, axis = 0)\n",
    "binding_labels = np.concatenate(binding_labels)\n",
    "TF_labels = np.concatenate(TF_labels)\n",
    "kept_TFs = np.unique(TF_labels)\n",
    "\n",
    "# Scale the features so that we can intepret input gradient later\n",
    "footprint_mean = np.mean(TFBS_data, axis = 0)[:-1]\n",
    "footprint_sd = np.std(TFBS_data, axis = 0)[:-1]\n",
    "TFBS_data[:, :-1] = (TFBS_data[:, :-1] - footprint_mean) / footprint_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f7ff427",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_TFs = np.unique(TF_labels)\n",
    "TF_bound_ratio = np.array([np.mean(binding_labels[TF_labels == TF]) for TF in kept_TFs])\n",
    "kept_TFs = kept_TFs[TF_bound_ratio > 0.1]\n",
    "TF_filter = [True if TF in kept_TFs else False for TF in TF_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67dd7613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ATF2', 'ATF3', 'ATF7', 'BHLHE40', 'CEBPA', 'CEBPB', 'CEBPG',\n",
       "       'CREB1', 'CREM', 'CTCF', 'EBF1', 'ELF1', 'ELF3', 'ETS1', 'ETV4',\n",
       "       'ETV5', 'FOSL2', 'FOXA2', 'FOXA3', 'GABPA', 'HLF', 'HNF1A',\n",
       "       'HNF4G', 'IRF4', 'JUN', 'JUNB', 'JUND', 'MAFF', 'MAFK', 'MAX',\n",
       "       'MLX', 'MXI1', 'NFE2L2', 'NFIA', 'NFIL3', 'NFKB1', 'NFKB2', 'NFYB',\n",
       "       'NFYC', 'NR2F2', 'NRF1', 'PAX5', 'PBX3', 'REL', 'RELA', 'RELB',\n",
       "       'RFX1', 'RFX3', 'RUNX3', 'RXRA', 'RXRB', 'SRF', 'TBX21', 'TCF3',\n",
       "       'TCF7', 'TEAD3', 'TEAD4', 'TFE3', 'USF1', 'USF2', 'YY1'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept_TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff508f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFBS_data_filt = TFBS_data[TF_filter, :]\n",
    "TF_labels_filt = TF_labels[TF_filter]\n",
    "binding_labels_filt = binding_labels[TF_filter]\n",
    "dataset_label_filt = dataset_label[TF_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13017403",
   "metadata": {},
   "source": [
    "### Preparing data for model training, optimization and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16012fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition data by dataset\n",
    "training_inds = [i for i in range(len(binding_labels_filt)) if dataset_label_filt[i] == \"HepG2\"]\n",
    "val_inds = [i for i in range(len(binding_labels_filt)) if dataset_label_filt[i] == \"GM12878\"]\n",
    "\n",
    "# Shuffle order of data\n",
    "np.random.shuffle(training_inds)\n",
    "np.random.shuffle(val_inds)\n",
    "\n",
    "# Get training data\n",
    "training_data = TFBS_data_filt[training_inds, :]\n",
    "training_target = binding_labels_filt[training_inds]\n",
    "\n",
    "# Get validation data\n",
    "val_data = TFBS_data_filt[val_inds, :]\n",
    "val_target = binding_labels_filt[val_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcb0f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional negative examples\n",
    "context_radius = 100\n",
    "context_len = context_radius * 2 + 1\n",
    "nucleosome_center = context_len * 4 + context_radius\n",
    "negative_data_ind = np.where(training_data[:, nucleosome_center] > 1)[0]\n",
    "negative_data = training_data[negative_data_ind, :]\n",
    "training_data = np.concatenate([training_data, negative_data], axis = 0)\n",
    "training_target = np.concatenate([training_target, np.zeros(len(negative_data_ind))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b97a5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_inv = []\n",
    "context_radius = 100\n",
    "context_len = context_radius * 2 + 1\n",
    "for i in range(6):\n",
    "    start = i * context_len\n",
    "    end = (i + 1) * context_len\n",
    "    training_data_inv.append(np.flip(training_data[:, start:end], axis = 1))\n",
    "training_data_inv = np.concatenate(training_data_inv, axis = 1)\n",
    "training_data_inv = np.concatenate([training_data_inv, np.reshape(training_data[:, 1206], (-1, 1))], axis = 1)\n",
    "training_data = np.concatenate([training_data, training_data_inv], axis = 0)\n",
    "training_target = np.concatenate([training_target, training_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065fbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuf_inds = np.arange(len(training_target))\n",
    "np.random.shuffle(shuf_inds)\n",
    "training_data = training_data[shuf_inds, :]\n",
    "training_target = training_target[shuf_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39371734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1887272, 1207)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c49ed1",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b39e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(training_data, training_target, val_data, val_target):\n",
    "    \n",
    "    # Initialize a Keras model for footprint-to-TF binding prediction\n",
    "    inputs = Input(shape = np.shape(training_data)[1])\n",
    "    fc_1 = Dense(128, activation = \"relu\")(inputs)\n",
    "    fc_2 = Dense(32, activation = \"relu\")(fc_1)\n",
    "    output = Dense(1, activation = \"sigmoid\")(fc_2)\n",
    "    model = keras.models.Model(inputs, output)\n",
    "    model.summary()\n",
    "    model.compile(optimizer = \"adam\",\n",
    "                  loss='binary_crossentropy', metrics=['binary_crossentropy'])\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    prev_loss = np.inf\n",
    "\n",
    "    # Model training\n",
    "    for n_epoch in range(10):\n",
    "\n",
    "        # New training epoch\n",
    "        model.fit(training_data, training_target, \n",
    "                  batch_size = 128, epochs = 1, \n",
    "                  validation_data = (val_data, val_target)) \n",
    "\n",
    "        # Calculate loss on validation set\n",
    "        val_pred = np.transpose(model.predict(val_data))[0]\n",
    "        bce_loss = loss(val_target, val_pred).numpy()\n",
    "\n",
    "        # If loss on validation set stops decreasing rapidly, stop training and adopt the previous saved version\n",
    "        if bce_loss - prev_loss > -0.001:\n",
    "            break\n",
    "        else:\n",
    "            prev_loss = bce_loss\n",
    "\n",
    "            # Save current model version\n",
    "            model.save(\"../../data/TFBSPrediction/TFBS_model.h5\")\n",
    "\n",
    "    # Load the last Tn5 bias model\n",
    "    model = load_model(\"../../data/TFBSPrediction/TFBS_model.h5\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63057dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(pred, target, TF_labels, threshold = 0.5, \n",
    "               TF_list = None, pred_bound_ratio_threshold = 0.1,\n",
    "               print_results = True):\n",
    "    \n",
    "    precision_list = []\n",
    "    recovery_list = []\n",
    "    pred_bound_list = []\n",
    "    pred_bound_r_list = []\n",
    "    AUPRC_list = []\n",
    "    n_site_list = []\n",
    "    kept_TFs = []\n",
    "    \n",
    "    # See if the user has a specified list of TFs they want to evaluate the model on\n",
    "    if TF_list is None:\n",
    "        TF_list = np.unique(TF_labels)\n",
    "    else:\n",
    "        TF_list = list(set(TF_list)&set(np.unique(TF_labels)))\n",
    "        \n",
    "    for TF in TF_list:\n",
    "\n",
    "        # Get prediction for a specific TF\n",
    "        TF_inds = np.array(TF_labels == TF)\n",
    "        pred_bound = pred[TF_inds] > threshold\n",
    "        if np.sum(pred_bound) == 0:\n",
    "            continue\n",
    "\n",
    "        # Calculate precision\n",
    "        precision = np.mean(target[TF_inds][pred_bound])\n",
    "\n",
    "        # Calculate percentage of motif sites that are predicted to be bound\n",
    "        pred_bound_r = np.mean(pred_bound)\n",
    "        \n",
    "        # Calculate number of true binding sites recovered\n",
    "        recovery = np.sum(target[TF_inds][pred_bound])\n",
    "        \n",
    "        # If predicted percentage of bound sites is very low, label this TF as inactive in this cell type\n",
    "        if pred_bound_r < pred_bound_ratio_threshold:\n",
    "            continue\n",
    "            \n",
    "        # Calculate area under precision-recall curve\n",
    "        AUPRC = average_precision_score(target[TF_inds], pred[TF_inds])\n",
    "            \n",
    "        # If the TF is considered active, record model performance\n",
    "        precision_list.append(precision)\n",
    "        pred_bound_list.append(np.sum(pred_bound))\n",
    "        pred_bound_r_list.append(pred_bound_r)\n",
    "        recovery_list.append(recovery)\n",
    "        AUPRC_list.append(AUPRC)\n",
    "        n_site_list.append(np.sum(TF_inds))\n",
    "        kept_TFs.append(TF)\n",
    "        \n",
    "        if print_results:\n",
    "            print(TF, \"AUROC\", round(auroc(target[TF_inds], pred[TF_inds]), 2),\n",
    "                  \"AUPRC\", round(AUPRC, 2),\n",
    "                  \"Precision\", round(precision, 3),\n",
    "                  \"Pred bound ratio\", round(pred_bound_r, 3),\n",
    "                  \"recovery\", round(recovery, 3),\n",
    "                  \"Number of motif matches\", np.sum(TF_inds))\n",
    "\n",
    "    # Filter out TFs with low binding signal\n",
    "    if print_results:\n",
    "        print(\"Median precision\", np.median(np.array(precision_list)))\n",
    "        print(\"Mean precision\", np.mean(np.array(precision_list)))\n",
    "        print(\"Median recovery\", np.median(np.array(recovery_list)))\n",
    "        print(\"Mean AURPC\", np.mean(np.array(AUPRC_list)))\n",
    "        print(\"Mean recovery\", np.mean(np.array(recovery_list)))\n",
    "    \n",
    "    eval_results = {\"precision\" : precision_list,\n",
    "                    \"recovery\" : recovery_list,\n",
    "                    \"pred_bound\" : pred_bound_list,\n",
    "                    \"pred_bound_r\" : pred_bound_r_list,\n",
    "                    \"AUPRC\" : AUPRC_list,\n",
    "                    \"n_site\": n_site_list,\n",
    "                    \"TFs\" : kept_TFs,}\n",
    "    \n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d89100a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 1207)]            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               154624    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 158,785\n",
      "Trainable params: 158,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "21403/21403 [==============================] - 82s 4ms/step - loss: 0.4003 - binary_crossentropy: 0.4003 - val_loss: 0.4249 - val_binary_crossentropy: 0.4249\n",
      "21403/21403 [==============================] - 82s 4ms/step - loss: 0.3893 - binary_crossentropy: 0.3893 - val_loss: 0.4192 - val_binary_crossentropy: 0.4192\n",
      "21403/21403 [==============================] - 80s 4ms/step - loss: 0.3869 - binary_crossentropy: 0.3869 - val_loss: 0.4190 - val_binary_crossentropy: 0.4190\n"
     ]
    }
   ],
   "source": [
    "model = model_training(training_data, training_target, \n",
    "                       val_data, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d7fb7a1-f1be-42a0-8bc3-8eee31edea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATF2 AUROC 0.7 AUPRC 0.49 Precision 0.639 Pred bound ratio 0.041 recovery 140 Number of motif matches 5369\n",
      "ATF3 AUROC 0.86 AUPRC 0.61 Precision 0.787 Pred bound ratio 0.055 recovery 365 Number of motif matches 8365\n",
      "ATF7 AUROC 0.79 AUPRC 0.77 Precision 0.831 Pred bound ratio 0.037 recovery 182 Number of motif matches 5998\n",
      "BHLHE40 AUROC 0.8 AUPRC 0.71 Precision 0.753 Pred bound ratio 0.046 recovery 250 Number of motif matches 7237\n",
      "CREB1 AUROC 0.88 AUPRC 0.85 Precision 0.923 Pred bound ratio 0.042 recovery 143 Number of motif matches 3694\n",
      "CREM AUROC 0.86 AUPRC 0.82 Precision 0.897 Pred bound ratio 0.047 recovery 165 Number of motif matches 3906\n",
      "CTCF AUROC 0.94 AUPRC 0.86 Precision 0.887 Pred bound ratio 0.195 recovery 7767 Number of motif matches 44947\n",
      "EBF1 AUROC 0.85 AUPRC 0.66 Precision 0.902 Pred bound ratio 0.011 recovery 266 Number of motif matches 26296\n",
      "ELF1 AUROC 0.82 AUPRC 0.57 Precision 0.796 Pred bound ratio 0.02 recovery 164 Number of motif matches 10428\n",
      "ETS1 AUROC 0.82 AUPRC 0.5 Precision 0.634 Pred bound ratio 0.02 recovery 104 Number of motif matches 8102\n",
      "GABPA AUROC 0.86 AUPRC 0.47 Precision 0.619 Pred bound ratio 0.027 recovery 213 Number of motif matches 12768\n",
      "IRF4 AUROC 0.8 AUPRC 0.38 Precision 0.576 Pred bound ratio 0.009 recovery 102 Number of motif matches 19047\n",
      "JUNB AUROC 0.8 AUPRC 0.64 Precision 0.787 Pred bound ratio 0.006 recovery 137 Number of motif matches 26847\n",
      "MAX AUROC 0.85 AUPRC 0.72 Precision 0.807 Pred bound ratio 0.011 recovery 71 Number of motif matches 7890\n",
      "NFKB1 AUROC 0.82 AUPRC 0.55 Precision 0.798 Pred bound ratio 0.005 recovery 79 Number of motif matches 21233\n",
      "NFKB2 AUROC 0.86 AUPRC 0.65 Precision 0.812 Pred bound ratio 0.004 recovery 91 Number of motif matches 25045\n",
      "NFYB AUROC 0.86 AUPRC 0.62 Precision 0.786 Pred bound ratio 0.014 recovery 147 Number of motif matches 13019\n",
      "PAX5 AUROC 0.8 AUPRC 0.38 Precision 0.452 Pred bound ratio 0.003 recovery 19 Number of motif matches 15417\n",
      "PBX3 AUROC 0.86 AUPRC 0.62 Precision 0.815 Pred bound ratio 0.004 recovery 53 Number of motif matches 16475\n",
      "REL AUROC 0.83 AUPRC 0.49 Precision 0.717 Pred bound ratio 0.005 recovery 76 Number of motif matches 20605\n",
      "RELA AUROC 0.85 AUPRC 0.55 Precision 0.793 Pred bound ratio 0.005 recovery 111 Number of motif matches 30246\n",
      "RELB AUROC 0.88 AUPRC 0.59 Precision 0.826 Pred bound ratio 0.003 recovery 38 Number of motif matches 13558\n",
      "RUNX3 AUROC 0.8 AUPRC 0.78 Precision 0.876 Pred bound ratio 0.006 recovery 78 Number of motif matches 15992\n",
      "TBX21 AUROC 0.83 AUPRC 0.54 Precision 0.667 Pred bound ratio 0.002 recovery 14 Number of motif matches 13914\n",
      "TCF3 AUROC 0.85 AUPRC 0.41 Precision 0.484 Pred bound ratio 0.001 recovery 15 Number of motif matches 24594\n",
      "USF1 AUROC 0.85 AUPRC 0.73 Precision 0.899 Pred bound ratio 0.042 recovery 489 Number of motif matches 12832\n",
      "USF2 AUROC 0.9 AUPRC 0.72 Precision 0.849 Pred bound ratio 0.044 recovery 462 Number of motif matches 12324\n",
      "Median precision 0.7961165048543689\n",
      "Mean precision 0.7634705159722114\n",
      "Median recovery 137.0\n",
      "Mean AURPC 0.6173719082362266\n",
      "Mean recovery 434.85185185185185\n"
     ]
    }
   ],
   "source": [
    "val_pred = np.transpose(model.predict(val_data))[0]\n",
    "eval_results = model_eval(val_pred, val_target, TF_labels[val_inds], \n",
    "                          threshold = 0.75, pred_bound_ratio_threshold = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60064aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 1207)]            0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               154624    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 158,785\n",
      "Trainable params: 158,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "24733/24733 [==============================] - 100s 4ms/step - loss: 0.4040 - binary_crossentropy: 0.4040 - val_loss: 0.4222 - val_binary_crossentropy: 0.4222\n",
      "24733/24733 [==============================] - 101s 4ms/step - loss: 0.3931 - binary_crossentropy: 0.3931 - val_loss: 0.4175 - val_binary_crossentropy: 0.4175\n",
      "24733/24733 [==============================] - 88s 4ms/step - loss: 0.3908 - binary_crossentropy: 0.3908 - val_loss: 0.4170 - val_binary_crossentropy: 0.4170\n",
      "24733/24733 [==============================] - 86s 3ms/step - loss: 0.3895 - binary_crossentropy: 0.3895 - val_loss: 0.4186 - val_binary_crossentropy: 0.4186\n"
     ]
    }
   ],
   "source": [
    "training_data = np.concatenate([training_data, val_data], axis = 0)\n",
    "training_target = np.concatenate([training_target, val_target], axis = 0)\n",
    "shuf_ind = np.arange(len(training_target))\n",
    "np.random.shuffle(shuf_ind)\n",
    "model = model_training(training_data[shuf_ind,:],\n",
    "                       training_target[shuf_ind], \n",
    "                       val_data, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa6dfd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the rescaling factor for later use\n",
    "with h5py.File(\"../../data/TFBSPrediction/TFBS_model.h5\", \"a\") as hf:\n",
    "    hf[\"footprint_mean\"] = footprint_mean\n",
    "    hf[\"footprint_sd\"] = footprint_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357530f4",
   "metadata": {},
   "source": [
    "### Calculate and visualize gradients with respect to input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9ab3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model gradients with respect to input\n",
    "# Helps to visualize what the model has learned\n",
    "def get_gradients(model, data):\n",
    "    \n",
    "    # Calculate gradients with respect to the input\n",
    "    data_tensor = tf.convert_to_tensor(data, dtype=tf.float32)\n",
    "    with tf.GradientTape() as t:\n",
    "        t.watch(data_tensor)\n",
    "        tape_output = model(data_tensor)\n",
    "    gradients = t.gradient(tape_output, data_tensor)\n",
    "\n",
    "    # Smoothe gradients\n",
    "    from scipy.signal import savgol_filter\n",
    "    smoothed_grad = savgol_filter(np.median(gradients, axis = 0)[:1206], 51, 3) \n",
    "    # window size 51, polynomial order 3\n",
    "    # np.median(gradients, axis = 0)[:-1] removes the last value which is gradient for motif match score\n",
    "    # We are now only interested in gradients with respect to footprint patterns\n",
    "\n",
    "    return smoothed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "980f471d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_ind = np.random.choice(np.arange(len(training_target)), 10000)\n",
    "smoothed_grad = get_gradients(model, training_data[sample_ind, :])\n",
    "\n",
    "# Visualize the learned greadients\n",
    "# Note that the scales here represent radius not diameter!\n",
    "# Diameter should be from 20 bp to 200 bp\n",
    "smoothed_grad = np.flip(np.reshape(smoothed_grad[:1206], (6, -1)), axis = 0)\n",
    "plt.figure(figsize = (15,8))\n",
    "ax = sns.heatmap(smoothed_grad, \n",
    "            yticklabels=[\"100bp\", \"80bp\", \"50bp\", \"30bp\", \"20bp\", \"10bp\",], \n",
    "            xticklabels=False, \n",
    "            vmax = 0.001, vmin = -0.001,\n",
    "            cmap = sns.color_palette(\"coolwarm\", as_cmap=True))\n",
    "plt.xticks(np.arange(0,250,50))\n",
    "ax.set_yticklabels(ax.get_yticklabels(),rotation = 0, fontsize = 15)\n",
    "ax.set_xticklabels(np.arange(0,250,50) - 100, fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c1e0d",
   "metadata": {},
   "source": [
    "### Test the model on an external dataset (e.g., another cell type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c6d8739",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/TFBSPrediction/TFBS_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/TFBSPrediction/TFBS_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m hf:\n\u001b[1;32m      3\u001b[0m     footprint_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(hf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfootprint_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = load_model(\"../../data/TFBSPrediction/TFBS_model.h5\")\n",
    "with h5py.File(\"../../data/TFBSPrediction/TFBS_model.h5\", \"r\") as hf:\n",
    "    footprint_mean = np.array(hf[\"footprint_mean\"])\n",
    "    footprint_sd = np.array(hf[\"footprint_sd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7be6ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_dataset = \"K562\" # Can be either \"GM12878\" or \"K562\"\n",
    "external_hf = h5py.File(\"../../data/\" + external_dataset + \"/TFBSDataUnibind.h5\", 'r')\n",
    "\n",
    "external_footprints = external_hf['motifFootprints']\n",
    "external_footprints = np.transpose(np.array(external_footprints))\n",
    "\n",
    "external_metadata = external_hf['metadata']\n",
    "external_metadata = np.array(external_metadata)\n",
    "\n",
    "external_TF_bound = np.array([i[0] for i in external_metadata])\n",
    "external_motif_scores = np.array([i[1] for i in external_metadata])\n",
    "external_TF_labels = np.array([i[2].decode('ascii') for i in external_metadata])\n",
    "external_kept_TFs = np.unique(external_TF_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a96c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features \n",
    "external_footprints = external_footprints - footprint_mean\n",
    "external_footprints = external_footprints / footprint_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a474bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all non-footprint features as additional features\n",
    "external_motif_scores = np.reshape(external_motif_scores, (-1, 1))\n",
    "external_data = np.concatenate([external_footprints, external_motif_scores], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "24be1f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOXK2 AUROC 0.79 AUPRC 0.39 Precision 0.667 Pred bound ratio 0.004 recovery 22 Number of motif matches 8376\n",
      "FOS AUROC 0.77 AUPRC 0.37 Precision 0.429 Pred bound ratio 0.02 recovery 151 Number of motif matches 17430\n",
      "HMBOX1 AUROC 0.68 AUPRC 0.38 Precision 0.444 Pred bound ratio 0.003 recovery 4 Number of motif matches 2985\n",
      "BHLHE40 AUROC 0.76 AUPRC 0.8 Precision 0.897 Pred bound ratio 0.056 recovery 252 Number of motif matches 4994\n",
      "JUND AUROC 0.76 AUPRC 0.75 Precision 0.886 Pred bound ratio 0.021 recovery 342 Number of motif matches 18296\n",
      "IRF2 AUROC 0.79 AUPRC 0.4 Precision 0.694 Pred bound ratio 0.005 recovery 34 Number of motif matches 10344\n",
      "NFYA AUROC 0.85 AUPRC 0.54 Precision 0.636 Pred bound ratio 0.04 recovery 208 Number of motif matches 8225\n",
      "FOSL1 AUROC 0.79 AUPRC 0.68 Precision 0.803 Pred bound ratio 0.023 recovery 354 Number of motif matches 19399\n",
      "CTCFL AUROC 0.82 AUPRC 0.4 Precision 0.424 Pred bound ratio 0.18 recovery 2199 Number of motif matches 28782\n",
      "MYC AUROC 0.85 AUPRC 0.51 Precision 0.614 Pred bound ratio 0.023 recovery 97 Number of motif matches 7017\n",
      "RFX1 AUROC 0.75 AUPRC 0.61 Precision 0.74 Pred bound ratio 0.037 recovery 165 Number of motif matches 5971\n",
      "CREB1 AUROC 0.86 AUPRC 0.84 Precision 0.867 Pred bound ratio 0.122 recovery 333 Number of motif matches 3139\n",
      "JUNB AUROC 0.79 AUPRC 0.45 Precision 0.594 Pred bound ratio 0.022 recovery 234 Number of motif matches 17986\n",
      "NR2F2 AUROC 0.77 AUPRC 0.48 Precision 0.682 Pred bound ratio 0.007 recovery 60 Number of motif matches 12120\n",
      "NRF1 AUROC 0.8 AUPRC 0.61 Precision 0.692 Pred bound ratio 0.135 recovery 1209 Number of motif matches 12958\n",
      "USF1 AUROC 0.77 AUPRC 0.83 Precision 0.896 Pred bound ratio 0.06 recovery 455 Number of motif matches 8476\n",
      "NFE2L2 AUROC 0.82 AUPRC 0.69 Precision 0.903 Pred bound ratio 0.019 recovery 250 Number of motif matches 14710\n",
      "MAFF AUROC 0.73 AUPRC 0.38 Precision 0.557 Pred bound ratio 0.019 recovery 108 Number of motif matches 10227\n",
      "CEBPG AUROC 0.7 AUPRC 0.54 Precision 0.863 Pred bound ratio 0.017 recovery 44 Number of motif matches 3023\n",
      "MAX AUROC 0.83 AUPRC 0.65 Precision 0.804 Pred bound ratio 0.018 recovery 78 Number of motif matches 5250\n",
      "NFIC AUROC 0.7 AUPRC 0.34 Precision 0.483 Pred bound ratio 0.025 recovery 257 Number of motif matches 21054\n",
      "GABPA AUROC 0.82 AUPRC 0.67 Precision 0.734 Pred bound ratio 0.089 recovery 502 Number of motif matches 7709\n",
      "CREM AUROC 0.78 AUPRC 0.83 Precision 0.868 Pred bound ratio 0.13 recovery 387 Number of motif matches 3437\n",
      "MXI1 AUROC 0.85 AUPRC 0.49 Precision 0.563 Pred bound ratio 0.028 recovery 112 Number of motif matches 7211\n",
      "ELF1 AUROC 0.84 AUPRC 0.6 Precision 0.668 Pred bound ratio 0.071 recovery 306 Number of motif matches 6423\n",
      "CTCF AUROC 0.87 AUPRC 0.77 Precision 0.833 Pred bound ratio 0.192 recovery 4351 Number of motif matches 27279\n",
      "ELK1 AUROC 0.83 AUPRC 0.58 Precision 0.671 Pred bound ratio 0.098 recovery 287 Number of motif matches 4370\n",
      "NFIA AUROC 0.71 AUPRC 0.49 Precision 0.553 Pred bound ratio 0.033 recovery 236 Number of motif matches 12901\n",
      "NFYB AUROC 0.81 AUPRC 0.58 Precision 0.69 Pred bound ratio 0.063 recovery 411 Number of motif matches 9428\n",
      "JUN AUROC 0.77 AUPRC 0.37 Precision 0.514 Pred bound ratio 0.021 recovery 166 Number of motif matches 15597\n",
      "MAFK AUROC 0.8 AUPRC 0.6 Precision 0.876 Pred bound ratio 0.015 recovery 169 Number of motif matches 12786\n",
      "USF2 AUROC 0.89 AUPRC 0.54 Precision 0.614 Pred bound ratio 0.064 recovery 307 Number of motif matches 7851\n",
      "ATF2 AUROC 0.73 AUPRC 0.82 Precision 0.9 Pred bound ratio 0.122 recovery 460 Number of motif matches 4195\n",
      "EGR1 AUROC 0.73 AUPRC 0.33 Precision 0.452 Pred bound ratio 0.038 recovery 345 Number of motif matches 20184\n",
      "NR2F1 AUROC 0.73 AUPRC 0.37 Precision 0.621 Pred bound ratio 0.01 recovery 64 Number of motif matches 10575\n",
      "NR2F6 AUROC 0.76 AUPRC 0.33 Precision 0.533 Pred bound ratio 0.011 recovery 57 Number of motif matches 9860\n",
      "MITF AUROC 0.84 AUPRC 0.51 Precision 0.643 Pred bound ratio 0.052 recovery 322 Number of motif matches 9691\n",
      "ELF4 AUROC 0.79 AUPRC 0.59 Precision 0.677 Pred bound ratio 0.069 recovery 357 Number of motif matches 7599\n",
      "YY1 AUROC 0.88 AUPRC 0.64 Precision 0.713 Pred bound ratio 0.038 recovery 271 Number of motif matches 10098\n",
      "TAL1 AUROC 0.77 AUPRC 0.52 Precision 0.731 Pred bound ratio 0.018 recovery 147 Number of motif matches 10918\n",
      "CEBPB AUROC 0.7 AUPRC 0.6 Precision 0.925 Pred bound ratio 0.009 recovery 49 Number of motif matches 5606\n",
      "Median precision 0.6818181818181818\n",
      "Mean precision 0.691449096921116\n",
      "Median recovery 250.0\n",
      "Mean AURPC 0.5583538482564088\n",
      "Mean recovery 394.1951219512195\n"
     ]
    }
   ],
   "source": [
    "external_pred = np.transpose(model.predict(external_data))[0]\n",
    "eval_results = model_eval(external_pred, external_TF_bound, external_TF_labels, threshold = 0.5,\n",
    "           TF_list = external_kept_TFs, pred_bound_ratio_threshold = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57600fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_metadata = pd.DataFrame(external_metadata)\n",
    "external_metadata[\"range\"] = [i.decode('ascii') for i in external_metadata[\"range\"]]\n",
    "external_metadata[\"TF\"] = [i.decode('ascii') for i in external_metadata[\"TF\"]]\n",
    "external_metadata[\"predScore\"] = external_pred\n",
    "external_metadata.to_csv(\"../../data/TFBSPrediction/\" + external_dataset + \"_pred_data.tsv\",\n",
    "                        sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a374e3-dea2-479f-aadf-56b6ea481b10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
